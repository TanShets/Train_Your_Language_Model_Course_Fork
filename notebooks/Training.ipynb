{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae25d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPTTransformer\n",
    "import torch\n",
    "from minbpe.gpt4 import GPT4Tokenizer\n",
    "from minbpe.basic import BasicTokenizer\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "tokenizer = BasicTokenizer()\n",
    "tokenizer.load(model_file='../output/tokenizer/temp_tokenizer.model')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "context_size = 512\n",
    "embedding_dimension = 256\n",
    "no_of_attention_heads = 8\n",
    "key_query_reduced_dimensionality = 8\n",
    "no_of_blocks = 16\n",
    "batch_size = 16\n",
    "vocab_size = len(tokenizer.vocab)+len(tokenizer.special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd7389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.664456\n"
     ]
    }
   ],
   "source": [
    "model = GPTTransformer(context_size, no_of_blocks, embedding_dimension, key_query_reduced_dimensionality, no_of_attention_heads)\n",
    "model = model.to(device)\n",
    "print(sum(i.numel() for i in model.parameters())/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3aff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''\n",
    "with open('../output/data.txt', 'r', encoding='utf-8') as fp:\n",
    "    data = '\\n'.join(fp.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acf9b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_seq = tokenizer.encode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bc02ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69874"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.tensor(token_seq, dtype=torch.long)\n",
    "splitter = int(0.95*len(input_data))\n",
    "\n",
    "training_data, test_data = input_data[:splitter], input_data[splitter:]\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9815902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataSet(Dataset):\n",
    "    def __init__(self, data: torch.Tensor, block_size: int):\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        x = self.data[index: index + self.block_size]\n",
    "        y = self.data[index + 1: index + self.block_size + 1]\n",
    "        return x, y\n",
    "\n",
    "def dataloaders(\n",
    "    train_data: torch.Tensor,\n",
    "    test_data: torch.Tensor,\n",
    "    block_size: int,\n",
    "    batch_size: int,\n",
    "    device: torch.device) -> Tuple[DataLoader, DataLoader]:\n",
    "    training_dataset = TextDataSet(train_data.to(device), block_size)\n",
    "    test_dataset = TextDataSet(test_data.to(device), block_size)\n",
    "\n",
    "    train_loader = DataLoader(training_dataset, batch_size = batch_size, shuffle = True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4a9e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = dataloaders(\n",
    "    train_data = training_data,\n",
    "    test_data = test_data,\n",
    "    block_size = context_size,\n",
    "    batch_size = batch_size,\n",
    "    device = device\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ce79337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_model_loss(\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    evaluation_iterations: int\n",
    ") -> Dict[str, float]:\n",
    "    losses = dict()\n",
    "    model.eval()\n",
    "    for test_type, loader in [('train', train_loader), ('test', test_loader)]:\n",
    "        loss = torch.zeros(evaluation_iterations)\n",
    "        index = 0\n",
    "        for x, y in loader:\n",
    "            if index >= evaluation_iterations:\n",
    "                break\n",
    "            with torch.no_grad():\n",
    "                _, loss_value = model(x, y)\n",
    "            loss[index] = loss_value.item()\n",
    "        losses[test_type] = loss.mean().item()\n",
    "    model.train()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba7eded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(\n",
    "    model: GPTTransformer,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch: int,\n",
    "    loss: float,\n",
    "    filename: str = \"checkpoint.pth\"\n",
    "):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'loss': loss,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e60a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "evaluation_iterations = 100\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "train_loader, test_loader = dataloaders(\n",
    "    train_data=training_data,\n",
    "    test_data=test_data,\n",
    "    block_size=context_size,\n",
    "    batch_size=batch_size,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "training_loss = []\n",
    "test_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24bad2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_index, (x, y) in enumerate(train_loader):\n",
    "        if batch_index % evaluation_iterations == 0 or batch_index == len(train_loader) - 1:\n",
    "            losses = get_model_loss(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                test_loader=test_loader,\n",
    "                evaluation_iterations=evaluation_iterations\n",
    "            )\n",
    "\n",
    "            print(f'Epoch: {epoch}, step: {batch_index}, train_loss: {losses['train']}, test_loss: {losses['test']}')\n",
    "        \n",
    "        output, loss = model(x, y)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    save_checkpoint(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        epoch=epoch,\n",
    "        loss=loss.item(),\n",
    "        filename=f'checkpoint_{epoch}.pth'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
